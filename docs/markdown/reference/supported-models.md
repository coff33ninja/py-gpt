# Supported Models

Complete list of AI models available in PyGPT.

## üìã Overview

PyGPT supports 100+ AI models from multiple providers. This reference lists all available models with their capabilities and specifications.

**Last Updated:** February 2026  
**PyGPT Version:** 2.7.10+

## ü§ñ OpenAI Models

### GPT-5 Series

**gpt-5**
- Context: 128K tokens
- Output: 16K tokens
- Multimodal: Yes
- Function calling: Yes
- Best for: Most capable, all tasks

**gpt-5.2**
- Context: 128K tokens
- Output: 16K tokens
- Multimodal: Yes
- Function calling: Yes
- Best for: Latest improvements

### GPT-4 Series

**gpt-4**
- Context: 8K tokens
- Output: 4K tokens
- Multimodal: No
- Function calling: Yes
- Best for: Complex reasoning

**gpt-4-turbo**
- Context: 128K tokens
- Output: 4K tokens
- Multimodal: Yes (vision)
- Function calling: Yes
- Best for: Long context tasks

**gpt-4o**
- Context: 128K tokens
- Output: 16K tokens
- Multimodal: Yes
- Function calling: Yes
- Best for: Fast, multimodal

**gpt-4o-mini**
- Context: 128K tokens
- Output: 16K tokens
- Multimodal: Yes
- Function calling: Yes
- Best for: Cost-effective

### o-Series (Reasoning)

**o1**
- Context: 128K tokens
- Output: 32K tokens
- Reasoning: Advanced
- Best for: Complex problems

**o3**
- Context: 128K tokens
- Output: 32K tokens
- Reasoning: Advanced
- Best for: Latest reasoning

**o4-mini**
- Context: 128K tokens
- Output: 32K tokens
- Reasoning: Good
- Best for: Cost-effective reasoning

### GPT-3.5 Series

**gpt-3.5-turbo**
- Context: 16K tokens
- Output: 4K tokens
- Function calling: Yes
- Best for: Fast, affordable

**gpt-3.5-turbo-instruct**
- Context: 4K tokens
- Output: 4K tokens
- Completion mode
- Best for: Text completion

### Realtime Models

**gpt-realtime**
- Audio: Native support
- Latency: Low
- Best for: Voice interaction

**gpt-4o-realtime-preview**
- Audio: Native support
- Multimodal: Yes
- Best for: Realtime multimodal

### Research Models

**o3-deep-research**
- Research: Deep analysis
- Sources: Multiple
- Best for: Comprehensive research

**o4-mini-deep-research**
- Research: Good analysis
- Cost: Lower
- Best for: Cost-effective research

## üî∑ Google Gemini Models

### Gemini 2.0 Series

**gemini-2.0-flash**
- Context: 1M tokens
- Multimodal: Yes
- Speed: Very fast
- Best for: Fast multimodal

**gemini-2.0-pro**
- Context: 2M tokens
- Multimodal: Yes
- Quality: Excellent
- Best for: Long context

### Gemini 1.5 Series

**gemini-1.5-pro**
- Context: 2M tokens
- Multimodal: Yes
- Quality: Excellent
- Best for: Massive context

**gemini-1.5-flash**
- Context: 1M tokens
- Multimodal: Yes
- Speed: Very fast
- Best for: Fast processing

### Specialized Models

**gemini-2.5-flash-preview-native-audio-dialog**
- Audio: Native
- Realtime: Yes
- Best for: Voice interaction

**gemini-2.5-computer-use-preview-10-2025**
- Computer use: Yes
- Automation: Yes
- Best for: System control

**deep-research-pro-preview-12-2025**
- Research: Deep
- Analysis: Comprehensive
- Best for: Research tasks

### Gemini 3

**gemini-3**
- Context: 2M+ tokens
- Multimodal: Yes
- Latest: Yes
- Best for: Cutting edge

## üü£ Anthropic Claude Models

### Claude 3.5 Series

**claude-3-5-sonnet**
- Context: 200K tokens
- Quality: Excellent
- Reasoning: Advanced
- Best for: Complex reasoning

**claude-sonnet-4.5**
- Context: 200K tokens
- Quality: Excellent
- Latest: Yes
- Best for: Latest improvements

### Claude 3 Series

**claude-3-opus**
- Context: 200K tokens
- Quality: Highest
- Cost: Higher
- Best for: Best quality

**claude-3-sonnet**
- Context: 200K tokens
- Quality: Very good
- Cost: Medium
- Best for: Balanced

**claude-3-haiku**
- Context: 200K tokens
- Quality: Good
- Cost: Low
- Best for: Fast, affordable

**claude-opus-4.5**
- Context: 200K tokens
- Quality: Highest
- Latest: Yes
- Best for: Latest best quality

## ‚ö° xAI Grok Models

**grok-2**
- Context: 128K tokens
- Real-time: Yes
- Quality: Very good
- Best for: Current information

**grok-2-mini**
- Context: 128K tokens
- Real-time: Yes
- Cost: Lower
- Best for: Cost-effective

**grok-4**
- Context: 128K tokens
- Real-time: Yes
- Latest: Yes
- Best for: Latest Grok

**grok-audio**
- Audio: Native
- Real-time: Yes
- Best for: Voice interaction

## üîç Perplexity Models

**sonar**
- Context: 127K tokens
- Web search: Yes
- Citations: Yes
- Best for: Quick research

**sonar-pro**
- Context: 127K tokens
- Web search: Deep
- Citations: Yes
- Best for: Deep research

**sonar-reasoning**
- Context: 127K tokens
- Reasoning: Advanced
- Web search: Yes
- Best for: Complex research

**sonar-chat**
- Context: 127K tokens
- Conversational: Yes
- Web search: Yes
- Best for: Interactive research

## üåä DeepSeek Models

**deepseek-v3**
- Context: 64K tokens
- Quality: Good
- Cost: Very low
- Best for: Cost-effective

**deepseek-r1**
- Context: 64K tokens
- Reasoning: Advanced
- Cost: Low
- Best for: Reasoning tasks

## üåü Mistral Models

**mistral-large**
- Context: 128K tokens
- Quality: Very good
- Speed: Fast
- Best for: European provider

**mistral-medium**
- Context: 32K tokens
- Quality: Good
- Cost: Medium
- Best for: Balanced

**mistral-small**
- Context: 32K tokens
- Quality: Good
- Cost: Low
- Best for: Affordable

**mistral-small3.1**
- Context: 32K tokens
- Quality: Good
- Latest: Yes
- Best for: Latest small model

## ü¶ô Ollama Models

**llama3**
- Context: 8K tokens
- Local: Yes
- Free: Yes
- Best for: Local, free

**llama3.1**
- Context: 128K tokens
- Local: Yes
- Free: Yes
- Best for: Long context, local

**mistral**
- Context: 32K tokens
- Local: Yes
- Free: Yes
- Best for: Fast, local

**deepseek-coder**
- Context: 16K tokens
- Local: Yes
- Code: Specialized
- Best for: Local coding

**gpt-oss**
- Context: 8K tokens
- Local: Yes
- Free: Yes
- Best for: Open source

**bielik**
- Context: 8K tokens
- Local: Yes
- Polish: Yes
- Best for: Polish language

## üñºÔ∏è Image Generation Models

### OpenAI

**dall-e-3**
- Resolution: Up to 1792x1024
- Quality: Excellent
- Style: Versatile

**dall-e-2**
- Resolution: Up to 1024x1024
- Quality: Good
- Cost: Lower

**gpt-image-1**
- Resolution: High
- Quality: Excellent
- Latest: Yes

**gpt-image-1.5**
- Resolution: High
- Quality: Excellent
- Latest: Yes

### Google

**imagen-3**
- Resolution: High
- Quality: Excellent
- Photorealistic: Yes

**imagen-4**
- Resolution: High
- Quality: Excellent
- Latest: Yes

### Other

**nano-banana-pro**
- Resolution: High
- Quality: Good
- Speed: Fast

## üé¨ Video Generation Models

**veo-3.0-generate-preview**
- Duration: Up to 60s
- Quality: High
- Resolution: 1080p

**veo-3.0-fast-generate-preview**
- Duration: Up to 30s
- Quality: Good
- Speed: Fast

**veo-3.1**
- Duration: Up to 60s
- Quality: High
- Latest: Yes

**sora-2**
- Duration: Up to 60s
- Quality: Excellent
- Realistic: Yes

## üéµ Audio Models

### Speech-to-Text

**whisper-1** (OpenAI)
- Languages: 50+
- Quality: Excellent
- Speed: Fast

### Text-to-Speech

**tts-1** (OpenAI)
- Voices: 6
- Quality: Good
- Speed: Fast

**tts-1-hd** (OpenAI)
- Voices: 6
- Quality: Excellent
- Speed: Medium

## üìä Model Comparison

### By Context Size

**Largest:**
1. Gemini 1.5 Pro - 2M tokens
2. Gemini 2.0 Pro - 2M tokens
3. Claude 3 - 200K tokens
4. GPT-4 Turbo - 128K tokens

### By Speed

**Fastest:**
1. Gemini Flash
2. Mistral models
3. DeepSeek
4. GPT-4o-mini

### By Cost

**Most Affordable:**
1. Ollama (Free)
2. Gemini (Free tier)
3. DeepSeek
4. GPT-3.5-turbo

### By Quality

**Highest Quality:**
1. GPT-5
2. Claude 3.5 Sonnet
3. Gemini 1.5 Pro
4. GPT-4

## üîó Related Resources

- [Provider Comparison](../providers/comparison.md)
- [API Key Setup](../guides/02-api-key-setup.md)
- [Model Configuration](./config-reference.md)

## üìù Notes

- Context sizes are maximum values
- Actual limits may vary by provider
- Pricing subject to change
- New models added regularly
- Check provider docs for latest info

## üÜò Need Help?

- Check [Provider Guides](../providers/)
- Visit [FAQ](../faq/general.md)
- Ask on [Discord](https://pygpt.net/discord)
- Report issues on [GitHub](https://github.com/szczyglis-dev/py-gpt/issues)

---

**Last Updated:** February 2026
