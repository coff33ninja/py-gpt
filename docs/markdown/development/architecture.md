# PyGPT Architecture Overview

Understanding PyGPT's structure and how components work together.

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           UI Layer (PySide/Qt)              â”‚
â”‚  â€¢ Chat Interface  â€¢ Settings â€¢ Plugins UI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Controller Layer (Business Logic)      â”‚
â”‚  â€¢ Chat Management  â€¢ File Handling         â”‚
â”‚  â€¢ Context Management â€¢ Command Execution   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Core Layer (PyGPT Core)              â”‚
â”‚  â€¢ Config Management  â€¢ Plugin System       â”‚
â”‚  â€¢ Database (SQLite)  â€¢ Indexing (LlamaIdx) â”‚
â”‚  â€¢ Audio/Vision Processing â€¢ Web Access    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Provider Layer (AI Services)           â”‚
â”‚  â€¢ OpenAI â€¢ Google â€¢ Anthropic â€¢ DeepSeek   â”‚
â”‚  â€¢ Local (Ollama) â€¢ Other Providers         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      External APIs (Cloud Services)         â”‚
â”‚  â€¢ LLM APIs (GPT, Gemini, etc.)             â”‚
â”‚  â€¢ Embeddings â€¢ Vector Stores               â”‚
â”‚  â€¢ Audio Services â€¢ Image Generation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Directory Structure

```
src/pygpt_net/
â”œâ”€â”€ app.py                 # Main application entry
â”œâ”€â”€ app_core.py           # Core orchestrator
â”œâ”€â”€ config.py             # Configuration management
â”œâ”€â”€ launcher.py           # Application launcher
â”œâ”€â”€ utils.py              # Utility functions
â”‚
â”œâ”€â”€ controller/           # UI Controllers & Logic
â”‚   â”œâ”€â”€ chat/            # Chat handling
â”‚   â”œâ”€â”€ context/         # Context management
â”‚   â”œâ”€â”€ files/           # File operations
â”‚   â”œâ”€â”€ model/           # Model selection
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ core/                # Core functionality
â”‚   â”œâ”€â”€ agents.py        # Agent system
â”‚   â”œâ”€â”€ assistants.py    # Assistant mode
â”‚   â”œâ”€â”€ audio.py         # Audio processing
â”‚   â”œâ”€â”€ bridge.py        # API bridge
â”‚   â”œâ”€â”€ calendar.py      # Calendar integration
â”‚   â”œâ”€â”€ camera.py        # Camera capture
â”‚   â”œâ”€â”€ command.py       # Command execution
â”‚   â”œâ”€â”€ db.py            # Database
â”‚   â”œâ”€â”€ filesystem.py    # File I/O
â”‚   â”œâ”€â”€ image.py         # Image operations
â”‚   â”œâ”€â”€ llm.py           # LLM interface
â”‚   â”œâ”€â”€ models.py        # Model management
â”‚   â”œâ”€â”€ plugins.py       # Plugin system
â”‚   â”œâ”€â”€ tokens.py        # Token counting
â”‚   â”œâ”€â”€ vision.py        # Vision processing
â”‚   â”œâ”€â”€ web.py           # Web access
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ provider/            # AI Provider Integrations
â”‚   â”œâ”€â”€ llms/            # LLM providers
â”‚   â”‚   â”œâ”€â”€ openai.py
â”‚   â”‚   â”œâ”€â”€ google.py
â”‚   â”‚   â”œâ”€â”€ anthropic.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ api/             # Provider API handlers
â”‚   â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”œâ”€â”€ google/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ audio_input/     # Speech recognition
â”‚   â”œâ”€â”€ audio_output/    # Text-to-speech
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ plugin/              # Plugin System
â”‚   â”œâ”€â”€ base.py          # Base plugin class
â”‚   â”œâ”€â”€ cmd_files.py     # File commands plugin
â”‚   â”œâ”€â”€ cmd_web.py       # Web search plugin
â”‚   â”œâ”€â”€ audio_input.py   # Audio input plugin
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ui/                  # User Interface
â”‚   â”œâ”€â”€ base/            # Base components
â”‚   â”œâ”€â”€ dialog/          # Dialog windows
â”‚   â”œâ”€â”€ layout/          # UI layouts
â”‚   â”œâ”€â”€ menu/            # Menus
â”‚   â””â”€â”€ widget/          # Custom widgets
â”‚
â”œâ”€â”€ item/                # Data Models
â”‚   â”œâ”€â”€ model.py         # ModelItem
â”‚   â”œâ”€â”€ context.py       # ContextItem
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                # Application Data
â”‚   â”œâ”€â”€ locale/          # Translations
â”‚   â”œâ”€â”€ models/          # Model definitions
â”‚   â”œâ”€â”€ icons/           # UI icons
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ migrations/          # Database migrations
```

---

## ğŸ”„ Data Flow Example: Chat Message

### User sends a message:

```
1. USER INPUT
   â””â”€â†’ Text typed in chat input box

2. UI LAYER
   â””â”€â†’ ChatController receives input
   â””â”€â†’ Validates message
   â””â”€â†’ Adds to UI (shows user message)

3. CORE PROCESSING
   â””â”€â†’ Get current model & config
   â””â”€â†’ Build prompt (with context/presets)
   â””â”€â†’ Count tokens
   â””â”€â†’ Prepare attachment data

4. PROVIDER LAYER
   â””â”€â†’ BridgeContext created
   â””â”€â†’ Select correct provider (OpenAI/Google/etc)
   â””â”€â†’ Prepare API request

5. EXTERNAL API
   â””â”€â†’ Send to LLM API
   â””â”€â†’ Stream response back
   â””â”€â†’ Handle errors/retries

6. POST-PROCESSING
   â””â”€â†’ Parse response
   â””â”€â†’ Extract commands (if any)
   â””â”€â†’ Execute commands (code, web search, etc)

7. STORAGE
   â””â”€â†’ Save to database
   â””â”€â†’ Update context history
   â””â”€â†’ Update embeddings (if RAG enabled)

8. UI UPDATE
   â””â”€â†’ Display AI response
   â””â”€â†’ Update token counter
   â””â”€â†’ Show status
```

---

## ğŸ”Œ Plugin System

### Plugin Architecture

```
PluginBase
â”œâ”€â”€ cmd_* plugins         # Commands (file, web, code, etc)
â”œâ”€â”€ audio_* plugins       # Audio (input, output)
â”œâ”€â”€ provider_* plugins    # Custom providers
â””â”€â”€ custom plugins        # User-created
```

### Plugin Lifecycle

```
1. Discovery
   â””â”€â†’ PyGPT scans plugins directory
   â””â”€â†’ Loads plugin metadata

2. Initialization
   â””â”€â†’ Plugin.__init__() called
   â””â”€â†’ Register handlers
   â””â”€â†’ Load configuration

3. Runtime
   â””â”€â†’ Plugin listens for events
   â””â”€â†’ Executes on triggers
   â””â”€â†’ Returns results

4. Shutdown
   â””â”€â†’ Plugin cleanup
   â””â”€â†’ Save state (if needed)
```

---

## ğŸ—„ï¸ Data Storage

### SQLite Database

```
database.db
â”œâ”€â”€ contexts          # Chat conversations
â”œâ”€â”€ attachments       # File attachments
â”œâ”€â”€ presets          # Prompt templates
â”œâ”€â”€ models           # Available models
â”œâ”€â”€ calendar         # Calendar entries
â”œâ”€â”€ notes            # User notes
â””â”€â”€ chat_history     # Full history
```

### File Storage

```
~/.pygpt/
â”œâ”€â”€ config.json      # Main configuration
â”œâ”€â”€ data/            # User data
â”‚   â”œâ”€â”€ contexts/    # Saved conversations
â”‚   â”œâ”€â”€ attachments/ # Uploaded files
â”‚   â”œâ”€â”€ models/      # Model cache
â”‚   â””â”€â”€ embeddings/  # Vector store
â””â”€â”€ cache/           # Temporary files
```

---

## ğŸ¤– AI Integration Points

### LLM Integration

```
ModelItem (config)
    â†“
Provider-specific wrapper (GoogleLLM, OpenAILLM, etc)
    â†“
LlamaIndex wrapper (for advanced features)
    â†“
External API calls
    â†“
Response processing
    â†“
Command extraction (if enabled)
    â†“
Result to UI
```

### Multi-Modal Support

```
Input types:
â”œâ”€â”€ Text messages
â”œâ”€â”€ Images (for vision models)
â”œâ”€â”€ Audio (for voice input)
â”œâ”€â”€ Files (for RAG)
â””â”€â”€ Real-time camera

Output types:
â”œâ”€â”€ Text responses
â”œâ”€â”€ Generated images
â”œâ”€â”€ Audio/speech
â”œâ”€â”€ Code execution results
â””â”€â”€ Web search results
```

---

## ğŸ” Security Architecture

### API Key Management
```
User API Key
    â†“
Encrypted storage (if enabled)
    â†“
Environment variable or config file
    â†“
Only sent to legitimate provider API
    â†“
Never logged or exposed
```

### Data Privacy
```
Chat data
    â†“
Stored locally by default
    â†“
Or sent to selected AI provider
    â†“
User responsible for provider's privacy policy
    â†“
No data sent elsewhere
```

---

## ğŸ§© Key Components

### BridgeContext
Central data container for API calls:
```python
BridgeContext {
    - messages: list        # Conversation history
    - model: ModelItem      # Selected model
    - prompt: str           # System prompt
    - attachments: list     # Files/images
    - temperature: float    # Model parameter
    - max_tokens: int       # Response limit
    - extra_params: dict    # Custom params
}
```

### ModelItem
Represents an AI model:
```python
ModelItem {
    - id: str               # Model identifier
    - name: str             # Display name
    - provider: str         # OpenAI, Google, etc
    - mode: str             # chat, completion, image
    - token_limit: int      # Context window
    - vision: bool          # Supports images
    - audio: bool           # Supports audio
}
```

### Config Manager
Centralized configuration:
```
config.get(key)         # Get value
config.set(key, value)  # Set value
config.save()           # Persist to disk
config.reset()          # Reset to defaults
```

---

## ğŸ”„ Mode System

### Operating Modes

```
Chat Mode
â””â”€â†’ Normal conversation with AI

Completion Mode
â””â”€â†’ Text completion/generation

Vision Mode
â””â”€â†’ Image analysis and generation

Assistant Mode
â””â”€â†’ OpenAI assistants with tools

Agent Mode
â””â”€â†’ Autonomous task execution

Langchain Mode
â””â”€â†’ Advanced chain operations

Audio Mode
â””â”€â†’ Real-time voice interaction

Research Mode
â””â”€â†’ Multi-source information gathering
```

---

## âš¡ Performance Considerations

### Optimization Strategies

1. **Caching**
   - Model cache
   - Response cache
   - Embedding cache

2. **Streaming**
   - Real-time response display
   - Reduces latency perception

3. **Threading**
   - API calls on background threads
   - Keeps UI responsive

4. **Lazy Loading**
   - Load features only when needed
   - Faster startup

---

## ğŸ§ª Testing Architecture

```
tests/
â”œâ”€â”€ unit/           # Individual component tests
â”œâ”€â”€ integration/    # Component interaction tests
â”œâ”€â”€ fixtures/       # Mock data
â””â”€â”€ conftest.py     # Test configuration
```

---

## ğŸ”„ Extensibility Points

### Adding New Features

1. **New Provider**: Create provider in `provider/llms/`
2. **New Plugin**: Extend `PluginBase` in `plugin/`
3. **New UI Component**: Create in `ui/widget/`
4. **New Data Type**: Add to `item/`
5. **New Command**: Add to plugin system

---

## ğŸ“Š Dependency Map

```
Core Dependencies:
â”œâ”€â”€ PySide6           # UI framework
â”œâ”€â”€ LlamaIndex        # RAG & indexing
â”œâ”€â”€ google-genai      # Google API
â”œâ”€â”€ openai            # OpenAI API
â”œâ”€â”€ anthropic         # Anthropic API
â”œâ”€â”€ sqlalchemy        # Database ORM
â”œâ”€â”€ pydantic          # Data validation
â””â”€â”€ pydub             # Audio processing

Optional Dependencies:
â”œâ”€â”€ chromadb          # Vector database
â”œâ”€â”€ requests          # HTTP client
â”œâ”€â”€ beautifulsoup4    # HTML parsing
â””â”€â”€ pillow            # Image processing
```

---

## ğŸš€ Development Workflow

### Making Changes

1. **Create feature branch**
2. **Modify code** in appropriate module
3. **Add tests** in `tests/`
4. **Run tests** to verify
5. **Update docs** if needed
6. **Create pull request**

### Adding a New Provider

1. Create `provider/llms/my_provider.py`
2. Extend `BaseLLM` class
3. Implement required methods:
   - `llama()` - LlamaIndex integration
   - `get_models()` - List available models
   - `setup_env()` - Environment setup
4. Register in provider registry
5. Add to UI model selector

---

## ğŸ“ˆ Scaling Considerations

### Future Enhancements

- Multi-GPU support
- Distributed processing
- Advanced caching strategies
- Model optimization (quantization, pruning)
- Mobile deployment

---

## ğŸ†˜ Getting Help

- **Architecture questions**: [GitHub Discussions](https://github.com/szczyglis-dev/py-gpt/discussions)
- **Code review**: [Pull Requests](https://github.com/szczyglis-dev/py-gpt/pulls)
- **Bug reports**: [GitHub Issues](https://github.com/szczyglis-dev/py-gpt/issues)

---

**Next**: [Plugin Development Guide](./plugin-development.md) â†’
